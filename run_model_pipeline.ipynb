{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import feat, mod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "today = feat.today_str()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condensed Model Pipeline\n",
    "* In this notebook, we put all of the functions from other files used in the ADS and hyperparameter tune for all three of the final models used in the ADS\n",
    "* To improve the runtime, we sample the data and only use data after 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor, Dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Setting the global seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# Just easier function to reset indices\n",
    "def split(data,test_size=1200,random_state=10):\n",
    "    train, test = train_test_split(data,test_size=test_size,random_state=random_state)\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    return train, test\n",
    "\n",
    "def split_weight(data,test_size=1200,weight='pred_split',random_state=10):\n",
    "    test = data.sample(test_size,weights='split_pred', random_state=random_state)\n",
    "    train = data[~data['uid'].isin(test['uid'])].reset_index(drop=True)\n",
    "    test.reset_index(drop=True,inplace=True)\n",
    "    return train, test\n",
    "\n",
    "# Just a wrapper around sklearn\n",
    "# so it returns a pandas dataframe with named\n",
    "# columns\n",
    "class DumEnc():\n",
    "    def __init__(self,dtype=int):\n",
    "        self.OHE = OneHotEncoder(dtype=dtype,\n",
    "                                 handle_unknown='ignore',\n",
    "                                 sparse=False)\n",
    "        self.var_names = None\n",
    "    def fit(self, X):\n",
    "        self.OHE.fit(X)\n",
    "        cats = self.OHE.categories_\n",
    "        var = list(X)\n",
    "        vn = []\n",
    "        for v,ca in zip(var,cats):\n",
    "            for c in ca:\n",
    "                vn.append(f'{v}_{c}')\n",
    "        self.var_names = vn\n",
    "    def transform(self,X):\n",
    "        res = pd.DataFrame(self.OHE.transform(X),\n",
    "                           columns=self.var_names,\n",
    "                           index=X.index)\n",
    "        return res\n",
    "\n",
    "def dummy_stats(values,begin_date):\n",
    "    vdate = pd.to_datetime(values,errors='ignore')\n",
    "    year = vdate.dt.year\n",
    "    month = vdate.dt.month\n",
    "    week_day = vdate.dt.dayofweek\n",
    "    diff_days = (vdate - begin_date).dt.days\n",
    "    # if binary, turn week/month into dummy variables\n",
    "    return diff_days, week_day, month, year\n",
    "\n",
    "def circle_stats(values,begin_date):\n",
    "    vdate = pd.to_datetime(values,errors='ignore')\n",
    "    within_year = vdate.dt.dayofyear\n",
    "    week_day = vdate.dt.dayofweek\n",
    "    # calculate sine/cosine for within year\n",
    "    year_cos = np.cos(within_year*(2*np.pi/365))\n",
    "    year_sin = np.sin(within_year*(2*np.pi/365))\n",
    "    # calculate sine/cosine for within week\n",
    "    week_cos = np.cos(week_day*(2*np.pi/7))\n",
    "    week_sin = np.sin(week_day*(2*np.pi/7))\n",
    "    diff_days = (vdate - begin_date).dt.days\n",
    "    return diff_days, year_cos, year_sin, week_cos, week_sin\n",
    "\n",
    "\n",
    "class DateEnc():\n",
    "    def __init__(self,\n",
    "                 begin = '1/1/2015',\n",
    "                 dummy = True,\n",
    "                 dum_types=['days','weekday','month']):\n",
    "        self.begin = pd.to_datetime(begin)\n",
    "        self.dummy = dummy\n",
    "        # 'days','weekday','month','year'\n",
    "        self.dum_types = dum_types\n",
    "        self.cat_vars = []\n",
    "        # Setting categorical variables\n",
    "    def fit(self,X):\n",
    "        # These are just fixed functions\n",
    "        pass\n",
    "    def transform(self,X):\n",
    "        vars = list(X)\n",
    "        res = []\n",
    "        res_labs = []\n",
    "        cat_labs = []\n",
    "        if self.dummy:\n",
    "            for v in vars:\n",
    "                dd, week_day, month, year = dummy_stats(X[v],self.begin)\n",
    "                if 'days' in self.dum_types:\n",
    "                    res.append(dd) # this is not likely to be categorical\n",
    "                    res_labs.append(f'days_{v}')\n",
    "                if 'weekday' in self.dum_types:\n",
    "                    res.append(week_day)\n",
    "                    res_labs.append(f'weekday_{v}')\n",
    "                    cat_labs.append(f'weekday_{v}')\n",
    "                if 'month' in self.dum_types:\n",
    "                    res.append(month)\n",
    "                    res_labs.append(f'month_{v}')\n",
    "                    cat_labs.append(f'weekday_{v}')\n",
    "                if 'year' in self.dum_types:\n",
    "                    res.append(year)\n",
    "                    res_labs.append(f'year_{v}')\n",
    "                    cat_labs.append(f'year_{v}')\n",
    "            self.cat_vars = cat_labs\n",
    "        else:\n",
    "             for v in vars:\n",
    "                dd, year_cos, year_sin, week_cos, week_sin = circle_stats(X[v],self.begin)\n",
    "                res += [dd, year_cos, year_sin, week_cos, week_sin]\n",
    "                res_labs += [f'days_{v}',f'yearcos_{v}',f'yearsin_{v}',f'weekcos_{v}',f'weeksin_{v}']\n",
    "        res_df = pd.concat(res,axis=1)\n",
    "        res_df.index = X.index\n",
    "        res_df.columns = res_labs\n",
    "        return res_df\n",
    "\n",
    "\n",
    "# Spline encoding\n",
    "# defaults to regular knots\n",
    "# or specified locations\n",
    "class SplEnc():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X):\n",
    "        pass\n",
    "    def transform(self,X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class IdentEnc():\n",
    "    def __init__(self):\n",
    "        self.note = None\n",
    "    def fit(self,X):\n",
    "        pass\n",
    "    def transform(self,X):\n",
    "        return X.copy()\n",
    "\n",
    "\n",
    "class SimpleOrdEnc():\n",
    "    def __init__(self,\n",
    "                 dtype=int,\n",
    "                 unknown_value=-1,\n",
    "                 lim_k=None,\n",
    "                 lim_count=None):\n",
    "        self.unknown_value = unknown_value\n",
    "        self.dtype = dtype\n",
    "        self.lim_k = lim_k\n",
    "        self.lim_count = lim_count\n",
    "        self.vars = None\n",
    "        self.soe = None\n",
    "    def fit(self, X):\n",
    "        self.vars = list(X)\n",
    "        # Now creating fit for each variable\n",
    "        res_oe = {}\n",
    "        for v in list(X):\n",
    "            res_oe[v] = OrdinalEncoder(dtype=self.dtype,\n",
    "                handle_unknown='use_encoded_value',\n",
    "                        unknown_value=self.unknown_value)\n",
    "            # Get unique values minus missing\n",
    "            xc = X[v].value_counts().reset_index()\n",
    "            xc.columns = [v, \"Freq\"]\n",
    "            # If lim_k, only taking top K value\n",
    "            if self.lim_k:\n",
    "                top_k = self.lim_k - 1\n",
    "                un_vals = xc.loc[0:top_k,:]\n",
    "            # If count, using that to filter\n",
    "            elif self.lim_count:\n",
    "                un_vals = xc[xc[\"Freq\"] >= self.lim_count].copy()\n",
    "            # If neither\n",
    "            else:\n",
    "                un_vals = xc\n",
    "            # Now fitting the encoder for one variable\n",
    "            res_oe[v].fit(un_vals[[v]])\n",
    "        # Appending back to the big class\n",
    "        self.soe = res_oe\n",
    "    # Defining transform/inverse_transform classes\n",
    "    def transform(self, X):\n",
    "        xcop = X[self.vars].copy()\n",
    "        for v in self.vars:\n",
    "            xcop[v] = self.soe[v].transform( X[[v]].fillna(self.unknown_value) )\n",
    "        return xcop\n",
    "    def fit_transform(self,X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    def inverse_transform(self, X):\n",
    "        xcop = X[self.vars].copy()\n",
    "        for v in self.vars:\n",
    "            xcop[v] = self.soe[v].inverse_transform( X[[v]].fillna(self.unknown_value) )\n",
    "        return xcop\n",
    "\n",
    "# You can compose multiple feature engines together\n",
    "# Such as DateEnc() and DumEnc()\n",
    "class ComposeFE():\n",
    "    def __init__(self,\n",
    "                mods):\n",
    "        # expects a dictionary\n",
    "        # of models\n",
    "        self.mods = mods\n",
    "    def fit(self,X):\n",
    "        trans = X.copy()\n",
    "        # goes left to right\n",
    "        for k,m in self.mods.items():\n",
    "            m.fit(trans)\n",
    "            trans = m.transform(trans)\n",
    "    def transform(self,X):\n",
    "        trans = X.copy()\n",
    "        for k,m in self.mods.items():\n",
    "            trans = m.transform(trans)\n",
    "        return trans\n",
    "\n",
    "\n",
    "class FeatureEngine():\n",
    "    def __init__(self,\n",
    "                 ord_vars = None,\n",
    "                 dum_vars = None,\n",
    "                 spl_vars = None,\n",
    "                 dat_vars = None,\n",
    "                 ide_vars = None,\n",
    "                 scale = None):\n",
    "        self.fin_vars = None\n",
    "        self.enc_dict = {}\n",
    "        self.ord_vars = ord_vars\n",
    "        self.dum_vars = dum_vars\n",
    "        self.spl_vars = spl_vars\n",
    "        self.dat_vars = dat_vars\n",
    "        self.ide_vars = ide_vars\n",
    "        self.cat_vars = None\n",
    "        self.ord = SimpleOrdEnc()\n",
    "        self.dum = DumEnc()\n",
    "        self.dat = DateEnc()\n",
    "        self.spl = SplEnc()\n",
    "        self.ide = IdentEnc()\n",
    "        self.scale = scale\n",
    "        enc_vars = [ord_vars,dum_vars,spl_vars,dat_vars,ide_vars]\n",
    "        enc_mods = [self.ord, self.dum, self.spl, self.dat, self.ide]\n",
    "        for v,m in zip(enc_vars,enc_mods):\n",
    "            if v is not None:\n",
    "                self.enc_dict[tuple(v)] = m\n",
    "    def fit(self, X):\n",
    "        res = []\n",
    "        for v,m in self.enc_dict.items():\n",
    "            m.fit(X[list(v)])\n",
    "            rf = m.transform(X[list(v)])\n",
    "            res.append(rf)\n",
    "        # doing a transform to know the variable names in the end\n",
    "        res_df = pd.concat(res,axis=1)\n",
    "        if self.scale is not None:\n",
    "            self.scale.fit(res_df)\n",
    "            res_df = pd.DataFrame(self.scale.transform(res_df),columns=list(res_df))\n",
    "        self.fin_vars = list(res_df)\n",
    "        # Adding categorical variables back in\n",
    "        cat_vars = []\n",
    "        if self.dum_vars is not None:\n",
    "            cat_vars += self.dum.var_names\n",
    "        if self.dat_vars is not None:\n",
    "            cat_vars += self.dat.cat_vars\n",
    "        if self.ord_vars is not None:\n",
    "            cat_vars += self.ord_vars\n",
    "        self.cat_vars = cat_vars\n",
    "        return res_df\n",
    "    def transform(self, X):\n",
    "        res = []\n",
    "        for v,m in self.enc_dict.items():\n",
    "            res.append(m.transform(X[list(v)]))\n",
    "        res_df = pd.concat(res,axis=1)\n",
    "        if self.scale is not None:\n",
    "            res_df = pd.DataFrame(self.scale.transform(res_df),columns=list(res_df))\n",
    "        return res_df\n",
    "\n",
    "def safelog(x):\n",
    "    return np.log(x.clip(1))\n",
    "\n",
    "def strat(values):\n",
    "    edges = [np.NINF,20000,1e6,1e7,1e8,np.inf]\n",
    "    labs = [1,2,3,4,5]\n",
    "    res = pd.cut(values,bins=edges,labels=labs,right=False)\n",
    "    return res.astype(int)\n",
    "\n",
    "\n",
    "# Class to insert different types of\n",
    "# regression models\n",
    "class RegMod():\n",
    "    def __init__(self,\n",
    "                 ord_vars = None,\n",
    "                 dum_vars = None,\n",
    "                 dat_vars = None,\n",
    "                 ide_vars = None,\n",
    "                        y = None,\n",
    "                transform = None,\n",
    "                inv_trans = None,\n",
    "                   weight = None,\n",
    "                  scale_x = None,\n",
    "                      mod = XGBRegressor(n_estimators=100, max_depth=3)):\n",
    "        self.fe = FeatureEngine(ord_vars=ord_vars,\n",
    "                           dat_vars=dat_vars,\n",
    "                           dum_vars=dum_vars,\n",
    "                           ide_vars=ide_vars,\n",
    "                           scale = scale_x)\n",
    "        self.transform = transform\n",
    "        self.inv_trans = inv_trans\n",
    "        self.mod = mod\n",
    "        self.y = y\n",
    "        self.resids = None\n",
    "        self.cat_vars = None\n",
    "        self.weight = weight\n",
    "        self.metrics = None\n",
    "        self.fit_cat = False\n",
    "    def fit(self, X, weight=True, cat=True):\n",
    "        if (self.weight is not None) & weight:\n",
    "            sw = X[self.weight]\n",
    "        else:\n",
    "            sw = None\n",
    "            #print('NOT using Weights in fit')\n",
    "        y_dat = X[self.y].copy()\n",
    "        if self.transform:\n",
    "            y_dat = self.transform(y_dat)\n",
    "        X_dat = self.fe.fit(X)\n",
    "        self.cat_vars = self.fe.cat_vars\n",
    "        # If catboost or lightgbm, pass in categories\n",
    "        if (type(self.mod) == CatBoostRegressor) & cat:\n",
    "            vt = list(X_dat)\n",
    "            if self.cat_vars is not None:\n",
    "                ci = [vt.index(c) for c in self.cat_vars]\n",
    "            else:\n",
    "                ci = None\n",
    "            self.mod.fit(X_dat,y_dat,sample_weight=sw,cat_features=ci)\n",
    "            self.fit_cat = True\n",
    "        elif (type(self.mod) == LGBMRegressor) & cat:\n",
    "            self.fit_cat = True\n",
    "            for v in self.cat_vars:\n",
    "                X_dat[v] = X_dat[v].astype('category')\n",
    "            self.mod.fit(X_dat, y_dat, sample_weight=sw)\n",
    "        else:\n",
    "            self.mod.fit(X_dat,y_dat,sample_weight=sw)\n",
    "        pred = self.mod.predict(X_dat)\n",
    "        self.resids = pd.Series(y_dat - pred)\n",
    "    def predict(self,X,duan=True):\n",
    "        X_dat = self.fe.transform(X)\n",
    "        if self.fit_cat & (type(self.mod) == LGBMRegressor):\n",
    "            for v in self.cat_vars:\n",
    "                X_dat[v] = X_dat[v].astype('category')\n",
    "        pred = pd.Series(self.mod.predict(X_dat), X.index)\n",
    "        resids = self.resids\n",
    "        # if transform, do Duans smearing\n",
    "        if (self.transform is not None) & duan:\n",
    "            resids = resids.values.reshape(1,resids.shape[0])\n",
    "            dp = self.inv_trans(pred.values.reshape(X.shape[0],1) + resids)\n",
    "            pred = pd.Series(dp.mean(axis=1), X.index)\n",
    "        return pred\n",
    "    def predict_int(self,X):\n",
    "        pred = self.predict(X)\n",
    "        if self.transform:\n",
    "            pred = strat(pred)\n",
    "        pred = pred.clip(1,5).round().astype(int)\n",
    "        return pred\n",
    "    def feat_import(self):\n",
    "        var_li = self.fe.fin_vars\n",
    "        mod_fi = self.mod.feature_importances_\n",
    "        res_df = pd.DataFrame(zip(var_li,mod_fi),columns = ['Var','FI'])\n",
    "        res_df.sort_values('FI',ascending=False,inplace=True,ignore_index=True)\n",
    "        # Normalize to sum to 1\n",
    "        res_df['FI'] = res_df['FI']/res_df['FI'].sum()\n",
    "        return res_df\n",
    "    def met_eval(self, data, weight=True, cat=True, full_train=False,\n",
    "                 split_tt='weighted', test_size=500, test_splits=10, \n",
    "                 ret=False, pr=False):\n",
    "        dc = data.copy()\n",
    "        seeds = np.random.randint(1,1e6,test_splits)\n",
    "        metrics = []\n",
    "        for s in seeds:\n",
    "            if split_tt == 'weighted':\n",
    "                if self.weight is not None:\n",
    "                    wv = self.weight\n",
    "                else:\n",
    "                    wv = 'pred_split'\n",
    "                train, test = split_weight(dc,test_size,wv,s)\n",
    "            else:\n",
    "                train, test = split(dc,test_size,s)\n",
    "            self.fit(train, weight, cat)\n",
    "            test['pred'] = self.predict_int(test)\n",
    "            met_di = rmse_region(test,ret=True)\n",
    "            met_di['seed'] = s\n",
    "            metrics.append(met_di.copy())\n",
    "        mpd = pd.DataFrame(metrics)\n",
    "        if full_train:\n",
    "            self.fit(data)\n",
    "        if self.metrics is None:\n",
    "            self.metrics = mpd\n",
    "        else:\n",
    "            self.metrics = pd.concat([self.metrics,mpd],axis=0)\n",
    "        if pr:\n",
    "            print(mpd[['AvgError','midwest','northeast','south','west']].describe().T)\n",
    "        if ret:\n",
    "            return mpd['AvgError'].mean()\n",
    "\n",
    "class CatMod():\n",
    "    def __init__(self,\n",
    "                 ord_vars = None,\n",
    "                 dum_vars = None,\n",
    "                 dat_vars = None,\n",
    "                 ide_vars = None,\n",
    "                        y = None,\n",
    "                transform = None,\n",
    "                inv_trans = None,\n",
    "                  scale_x = None,\n",
    "                      mod = CatBoostClassifier(iterations=100,depth=5,allow_writing_files=False,verbose=False)\n",
    "                      ):\n",
    "        self.fe = FeatureEngine(ord_vars=ord_vars,\n",
    "                           dat_vars=dat_vars,\n",
    "                           dum_vars=dum_vars,\n",
    "                           ide_vars=ide_vars,\n",
    "                           scale = scale_x)\n",
    "        self.mod = mod\n",
    "        self.y = y\n",
    "        self.cat_vars = None\n",
    "    def fit(self, X, sample_weight=None):\n",
    "        y_dat = X[self.y].copy().astype(int)\n",
    "        X_dat = self.fe.fit(X)\n",
    "        self.mod.fit(X_dat,y_dat,sample_weight=sample_weight)\n",
    "    def predict_proba(self,X):\n",
    "        X_dat = self.fe.transform(X)\n",
    "        pred_probs = self.mod.predict_proba(X_dat)\n",
    "        # Turning into nicer dataframe\n",
    "        cols = [f'P{str(i)}' for i in range(pred_probs.shape[1])]\n",
    "        pred_probs = pd.DataFrame(pred_probs,index=X.index, columns=cols)\n",
    "        return pred_probs\n",
    "    def predict(self,X):\n",
    "        # returns predicted probability\n",
    "        pred = self.predict_proba(X)\n",
    "        return pred[\"P1\"]\n",
    "    def feat_import(self):\n",
    "        var_li = self.fe.fin_vars\n",
    "        mod_fi = self.mod.feature_importances_\n",
    "        res_df = pd.DataFrame(zip(var_li,mod_fi),columns = ['Var','FI'])\n",
    "        res_df.sort_values('FI',ascending=False,inplace=True,ignore_index=True)\n",
    "        # Normalize to sum to 1\n",
    "        res_df['FI'] = res_df['FI']/res_df['FI'].sum()\n",
    "        return res_df\n",
    "\n",
    "# If you pass in multiple models\n",
    "# this will ensemble them, presumes regressor models\n",
    "class EnsMod():\n",
    "    def __init__(self, mods, av_func = 'mean'):\n",
    "        self.mods = mods #should be dict\n",
    "        self.av_func = av_func\n",
    "    def fit(self,X,weight=True,cat=True):\n",
    "        for key,mod in self.mods.items():\n",
    "            mod.fit(X,weight=weight,cat=cat)\n",
    "    def predict(self,X):\n",
    "        res = []\n",
    "        for key,mod in self.mods.items():\n",
    "            res.append(mod.predict(X))\n",
    "        res_df = pd.concat(res,axis=1)\n",
    "        if self.av_func == 'mean':\n",
    "            pred = res_df.mean(axis=1)\n",
    "        return pred\n",
    "    def predict_int(self,X):\n",
    "        pred = self.predict(X)\n",
    "        pred = pred.clip(1,5).round().astype(int)\n",
    "        return pred\n",
    "\n",
    "def rmse_region(data,pred='pred',true='severity',region='region',scale=False,ret=False):\n",
    "    dc = data[[region,true,pred]].copy()\n",
    "    if scale:\n",
    "        dc[pred] = strat(dc[pred])\n",
    "    dc[pred] = dc[pred].round().astype(int).clip(1,5)\n",
    "    dc[region] = dc[region].replace({1:'northeast',\n",
    "                                     2:'south',\n",
    "                                     3:'midwest',\n",
    "                                     4:'west'})\n",
    "    dc['sq_error'] = (dc[true] - dc[pred])**2\n",
    "    gr_val = dc.groupby(region,as_index=False)['sq_error'].mean()\n",
    "    gr_val['root_mse'] = np.sqrt(gr_val['sq_error'])\n",
    "    avg_error = gr_val['root_mse'].mean()\n",
    "    if ret:\n",
    "        regions = gr_val['region'].tolist()\n",
    "        regions.append('AvgError')\n",
    "        vals = gr_val['root_mse'].tolist()\n",
    "        vals.append(avg_error)\n",
    "        gr_di = {r:v for r,v in zip(regions,vals)}\n",
    "        return gr_di\n",
    "    else:\n",
    "        print(f'\\nAverage error {avg_error:.4f}')\n",
    "        print('\\nRegion Error')\n",
    "        print(gr_val[['region','root_mse']])\n",
    "\n",
    "def save_model(mod,name):\n",
    "    fname = f'./models/{name}.pkl'\n",
    "    outfile = open(fname,\"wb\")\n",
    "    pickle.dump(mod,outfile)\n",
    "    outfile.close()\n",
    "\n",
    "def load_model(name):\n",
    "    fname = f'./models/{name}.pkl'\n",
    "    infile = open(fname, \"rb\")\n",
    "    mod = pickle.load(infile)\n",
    "    infile.close()\n",
    "    return mod\n",
    "\n",
    "\n",
    "# function to check if similar to any past submissions\n",
    "def check_similar(current):\n",
    "    files = os.listdir(\"./submissions\")\n",
    "    for fi in files:\n",
    "        old = pd.read_csv(f\"./submissions/{fi}\")\n",
    "        dif = np.abs(current['severity'] - old['severity']).sum()\n",
    "        if dif == 0:\n",
    "            print(f'Date {fi} same as current')\n",
    "\n",
    "\n",
    "def check_day(current,day=\"sub_2023_01_31.csv\"):\n",
    "    old = pd.read_csv(fr\"./submissions/{day}\")\n",
    "    dstr = f'dif_{day[4:-4]}'\n",
    "    current[dstr] = old['severity'] - current['severity']\n",
    "    print(current[dstr].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def today_str():\n",
    "    now = datetime.now()\n",
    "    return now.strftime('%Y_%m_%d')\n",
    "\n",
    "\n",
    "reg_ord = {'west':4,\n",
    "           'midwest':3,\n",
    "           'south':2,\n",
    "           'northeast':1}\n",
    "\n",
    "# ordinal encoding for region\n",
    "def org_reg(data,rstr='region'):\n",
    "    data[rstr] = data[rstr].replace(reg_ord)\n",
    "\n",
    "def filter_reg(data, region):\n",
    "    return data.loc[data['region']==region]\n",
    "\n",
    "def subsample(data, n):\n",
    "    nrows = data.shape[0]\n",
    "    stratified_sample, _ = train_test_split(data, test_size=1 - (n/nrows), stratify=data['region'])\n",
    "    return stratified_sample\n",
    "\n",
    "def filter_time(data):\n",
    "    return data.loc[data['date'].dt.year > 2016]\n",
    "\n",
    "def ord_imtype(data,imstr='imtype'):\n",
    "    rep_di = {'land_sat':0,\n",
    "              'sentinel':1}\n",
    "    data[imstr] = data[imstr].fillna(-1).replace(rep_di)\n",
    "\n",
    "\n",
    "def filter_landsat(data):\n",
    "    rep_di = {'land_sat':0,\n",
    "              'sentinel':1}\n",
    "    data['imtype'] = data['imtype'].fillna(-1).replace(rep_di)\n",
    "    im_vars = ['prop_lake_500', 'r_500', 'g_500', 'b_500']\n",
    "    im_vars += ['prop_lake_1000', 'r_1000', 'g_1000', 'b_1000']\n",
    "    im_vars += ['prop_lake_2500', 'r_2500', 'g_2500', 'b_2500']\n",
    "    im_vars += ['imtype']\n",
    "    landsat = data['imtype'] == 0\n",
    "    data.loc[landsat,im_vars] = -1\n",
    "\n",
    "def safesqrt(values):\n",
    "    return np.sqrt(values.clip(0))\n",
    "\n",
    "def safelog(x):\n",
    "    return np.log(x.clip(1))\n",
    "\n",
    "def strat(values):\n",
    "    edges = [np.NINF,20000,1e6,1e7,1e8,np.inf]\n",
    "    labs = [1,2,3,4,5]\n",
    "    res = pd.cut(values,bins=edges,labels=labs,right=False)\n",
    "    return res.astype(int)\n",
    "\n",
    "# Looking at train/test\n",
    "# there are a few clusters, want\n",
    "# to make sure to predict these well\n",
    "def cluster(x):\n",
    "    lat, lon = x[0], x[1]\n",
    "    if (lat < 41) & (lon < -116):\n",
    "        # cali\n",
    "        return 7\n",
    "    elif (lat < 41) & (lat > 36.29) & (lon < -92.9) & (lon > -102.2):\n",
    "        # midwest\n",
    "        return 6\n",
    "    elif (lat < 38.14) & (lat > 33.26) & (lon < -74.8) & (lon > -85.52):\n",
    "        # carolina\n",
    "        return 2\n",
    "    elif (lat < 43) & (lat > 38.7) & (lon < -75.4) & (lon > -83.55):\n",
    "        # erie\n",
    "        return 3\n",
    "    elif (lat < 43.1) & (lat > 40.7) & (lon < -69.5) & (lon > -74.6):\n",
    "        # mass\n",
    "        return 4\n",
    "    elif (lat < 49.6) & (lat > 41.5) & (lon < -83.55) & (lon > -104.56):\n",
    "        # dakota\n",
    "        return 1\n",
    "    else:\n",
    "        # other\n",
    "        return 5\n",
    "\n",
    "#                  1   2      2   3    3     4   4    5   5\n",
    "#te_st = pd.Series([1,20000,30000,1e6,1e6+1,1e7,1e7+1,1e8,1e9])\n",
    "#print(strat(te_st))\n",
    "\n",
    "db = './data/data.sqlite'\n",
    "\n",
    "train_query = \"\"\"\n",
    "SELECT \n",
    "  m.uid,\n",
    "  l.region,\n",
    "  l.severity,\n",
    "  l.density,\n",
    "  m.latitude,\n",
    "  m.longitude,\n",
    "  m.date,\n",
    "  e.elevation,\n",
    "  e.mine,\n",
    "  e.maxe,\n",
    "  e.dife,\n",
    "  e.avge,\n",
    "  e.stde,\n",
    "  sl.severity_100,\n",
    "  sl.logDensity_100,\n",
    "  sl.count_100,\n",
    "  sl.severity_300,\n",
    "  sl.logDensity_300,\n",
    "  sl.count_300,\n",
    "  sl.severity_1000,\n",
    "  sl.logDensity_1000,\n",
    "  sl.count_1000,\n",
    "  st.imtype,\n",
    "  st.prop_lake_500,\n",
    "  st.r_500,\n",
    "  st.g_500,\n",
    "  st.b_500,\n",
    "  st.prop_lake_1000,\n",
    "  st.r_1000,\n",
    "  st.g_1000,\n",
    "  st.b_1000,\n",
    "  st.prop_lake_2500,\n",
    "  st.r_2500,\n",
    "  st.g_2500,\n",
    "  st.b_2500\n",
    "FROM meta AS m\n",
    "LEFT JOIN elevation_dem AS e\n",
    "  ON m.uid = e.uid\n",
    "LEFT JOIN spat_lag AS sl\n",
    "  ON m.uid = sl.uid\n",
    "LEFT JOIN sat AS st\n",
    "  ON m.uid = st.uid\n",
    "LEFT JOIN labels AS l\n",
    "  ON m.uid = l.uid\n",
    "WHERE\n",
    "  m.split = 'train'\n",
    "\"\"\"\n",
    "\n",
    "test_query = \"\"\"\n",
    "SELECT \n",
    "  m.uid,\n",
    "  l.region,\n",
    "  m.latitude,\n",
    "  m.longitude,\n",
    "  m.date,\n",
    "  e.elevation,\n",
    "  e.mine,\n",
    "  e.maxe,\n",
    "  e.dife,\n",
    "  e.avge,\n",
    "  e.stde,\n",
    "  sl.severity_100,\n",
    "  sl.logDensity_100,\n",
    "  sl.count_100,\n",
    "  sl.severity_300,\n",
    "  sl.logDensity_300,\n",
    "  sl.count_300,\n",
    "  sl.severity_1000,\n",
    "  sl.logDensity_1000,\n",
    "  sl.count_1000,\n",
    "  st.imtype,\n",
    "  st.prop_lake_500,\n",
    "  st.r_500,\n",
    "  st.g_500,\n",
    "  st.b_500,\n",
    "  st.prop_lake_1000,\n",
    "  st.r_1000,\n",
    "  st.g_1000,\n",
    "  st.b_1000,\n",
    "  st.prop_lake_2500,\n",
    "  st.r_2500,\n",
    "  st.g_2500,\n",
    "  st.b_2500\n",
    "FROM meta AS m\n",
    "LEFT JOIN elevation_dem AS e\n",
    "  ON m.uid = e.uid\n",
    "LEFT JOIN spat_lag AS sl\n",
    "  ON m.uid = sl.uid\n",
    "LEFT JOIN sat AS st\n",
    "  ON m.uid = st.uid\n",
    "LEFT JOIN format AS l\n",
    "  ON m.uid = l.uid\n",
    "WHERE\n",
    "  m.split = 'test'\n",
    "\"\"\"\n",
    "\n",
    "def add_table(data,tab_name,db_str=db):\n",
    "    db_con = sqlite3.connect(db_str)\n",
    "    dn = data.copy()\n",
    "    dn['DateTime'] = pd.to_datetime('now',utc=True)\n",
    "    dn.to_sql(tab_name,index=False,if_exists='replace',con=db_con)\n",
    "\n",
    "\n",
    "def get_both(db_str=db,split_pred=False):\n",
    "    r1 = get_data('train',db_str,split_pred)\n",
    "    r1['test'] = 0\n",
    "    r1.drop(columns=['severity','density','logDensity'],inplace=True)\n",
    "    r2 = get_data('test',db_str,split_pred)\n",
    "    r2['test'] = 1\n",
    "    res_df = pd.concat([r1,r2],axis=0)\n",
    "    return res_df.reset_index(drop=True)\n",
    "\n",
    "def get_data(region, data_type='train',db_str=db,split_pred=False):\n",
    "    db_con = sqlite3.connect(db_str)\n",
    "    if data_type == 'train':\n",
    "        sql = train_query\n",
    "    elif data_type == 'test':\n",
    "        sql = test_query\n",
    "    dat = pd.read_sql(sql,con=db_con)\n",
    "    org_reg(dat) # Region ordinal encode\n",
    "    # Winning solution used landsat-7 data\n",
    "    #ord_imtype(dat) # image type landsat/sentinel\n",
    "    filter_landsat(dat) # filtering mistake landsat-7 info\n",
    "    dat = dat.fillna(-1) # missing a bit of sat data\n",
    "    dat['cluster'] = dat[['latitude','longitude']].apply(cluster,axis=1)\n",
    "    dat['date'] = pd.to_datetime(dat['date'])\n",
    "    #dat = filter_time(dat)\n",
    "    dat = subsample(dat, 3000)\n",
    "    if data_type == 'train':\n",
    "        dat['logDensity'] = safelog(dat['density'])\n",
    "    if split_pred:\n",
    "        pred_test = pd.read_sql('SELECT uid, pred AS split_pred FROM split_pred',con=db_con)\n",
    "        dat = dat.merge(pred_test,on='uid')\n",
    "    return dat\n",
    "\n",
    "\n",
    "# Need logic to take predictions and get them in the right order\n",
    "def sub_format(data,pred='pred'):\n",
    "    form = pd.read_csv('./data/submission_format.csv')\n",
    "    # some logic to transform predictions via Duan\n",
    "    # smearing\n",
    "    dp = data[[pred,'uid']].copy()\n",
    "    dp[pred] = dp[pred].round().astype(int).clip(1,5)\n",
    "    mf = form.merge(dp,on='uid')\n",
    "    mf['severity'] = mf['pred']\n",
    "    return mf[['uid','region','severity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows: 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>elevation</th>\n",
       "      <th>mine</th>\n",
       "      <th>maxe</th>\n",
       "      <th>...</th>\n",
       "      <th>r_1000</th>\n",
       "      <th>g_1000</th>\n",
       "      <th>b_1000</th>\n",
       "      <th>prop_lake_2500</th>\n",
       "      <th>r_2500</th>\n",
       "      <th>g_2500</th>\n",
       "      <th>b_2500</th>\n",
       "      <th>cluster</th>\n",
       "      <th>logDensity</th>\n",
       "      <th>split_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fqgs</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.178000e+03</td>\n",
       "      <td>35.760000</td>\n",
       "      <td>-79.080423</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>146.694702</td>\n",
       "      <td>109.315704</td>\n",
       "      <td>188.736801</td>\n",
       "      <td>...</td>\n",
       "      <td>89.406199</td>\n",
       "      <td>93.579539</td>\n",
       "      <td>64.070762</td>\n",
       "      <td>0.123018</td>\n",
       "      <td>102.153358</td>\n",
       "      <td>103.579304</td>\n",
       "      <td>73.087821</td>\n",
       "      <td>2</td>\n",
       "      <td>7.686162</td>\n",
       "      <td>0.006156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zftw</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.160300e+04</td>\n",
       "      <td>35.874773</td>\n",
       "      <td>-78.875949</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>105.848808</td>\n",
       "      <td>83.983261</td>\n",
       "      <td>124.047012</td>\n",
       "      <td>...</td>\n",
       "      <td>156.888269</td>\n",
       "      <td>149.170216</td>\n",
       "      <td>129.271129</td>\n",
       "      <td>0.200466</td>\n",
       "      <td>155.682271</td>\n",
       "      <td>144.419041</td>\n",
       "      <td>122.544214</td>\n",
       "      <td>2</td>\n",
       "      <td>9.980587</td>\n",
       "      <td>0.003530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irwx</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.109977e+06</td>\n",
       "      <td>38.152600</td>\n",
       "      <td>-121.501000</td>\n",
       "      <td>2018-02-20</td>\n",
       "      <td>-4.117393</td>\n",
       "      <td>-5.789963</td>\n",
       "      <td>4.253438</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>14.562188</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ntpv</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.643495e+02</td>\n",
       "      <td>44.100000</td>\n",
       "      <td>-82.116667</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5.898114</td>\n",
       "      <td>0.024854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wtii</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.471703e+06</td>\n",
       "      <td>37.412500</td>\n",
       "      <td>-120.759000</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>39.815010</td>\n",
       "      <td>33.527100</td>\n",
       "      <td>44.856056</td>\n",
       "      <td>...</td>\n",
       "      <td>208.540800</td>\n",
       "      <td>168.512684</td>\n",
       "      <td>127.900014</td>\n",
       "      <td>0.489830</td>\n",
       "      <td>212.852484</td>\n",
       "      <td>172.177925</td>\n",
       "      <td>129.966744</td>\n",
       "      <td>7</td>\n",
       "      <td>14.201931</td>\n",
       "      <td>0.006923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  region  severity       density   latitude   longitude       date  \\\n",
       "0  fqgs       2         1  2.178000e+03  35.760000  -79.080423 2020-05-13   \n",
       "1  zftw       2         2  2.160300e+04  35.874773  -78.875949 2020-09-24   \n",
       "2  irwx       4         4  2.109977e+06  38.152600 -121.501000 2018-02-20   \n",
       "3  ntpv       3         1  3.643495e+02  44.100000  -82.116667 2018-04-03   \n",
       "4  wtii       4         4  1.471703e+06  37.412500 -120.759000 2021-05-11   \n",
       "\n",
       "    elevation        mine        maxe  ...      r_1000      g_1000  \\\n",
       "0  146.694702  109.315704  188.736801  ...   89.406199   93.579539   \n",
       "1  105.848808   83.983261  124.047012  ...  156.888269  149.170216   \n",
       "2   -4.117393   -5.789963    4.253438  ...   -1.000000   -1.000000   \n",
       "3  173.500000  173.500000  173.500000  ...   -1.000000   -1.000000   \n",
       "4   39.815010   33.527100   44.856056  ...  208.540800  168.512684   \n",
       "\n",
       "       b_1000  prop_lake_2500      r_2500      g_2500      b_2500  cluster  \\\n",
       "0   64.070762        0.123018  102.153358  103.579304   73.087821        2   \n",
       "1  129.271129        0.200466  155.682271  144.419041  122.544214        2   \n",
       "2   -1.000000       -1.000000   -1.000000   -1.000000   -1.000000        7   \n",
       "3   -1.000000       -1.000000   -1.000000   -1.000000   -1.000000        5   \n",
       "4  127.900014        0.489830  212.852484  172.177925  129.966744        7   \n",
       "\n",
       "   logDensity  split_pred  \n",
       "0    7.686162    0.006156  \n",
       "1    9.980587    0.003530  \n",
       "2   14.562188    0.001335  \n",
       "3    5.898114    0.024854  \n",
       "4   14.201931    0.006923  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dat = get_data(1, split_pred=True)\n",
    "print(\"num rows:\", train_dat.shape[0])\n",
    "train_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example just predicting severity directly\n",
    "sat_500 = ['prop_lake_500', 'r_500', 'g_500', 'b_500']\n",
    "sat_1000 = ['prop_lake_1000', 'r_1000', 'g_1000', 'b_1000']\n",
    "sat_2500 = ['prop_lake_2500', 'r_2500', 'g_2500', 'b_2500']\n",
    "sat_1025 = ['prop_lake_2500', 'r_2500', 'g_2500', 'b_2500', \n",
    "           'prop_lake_1000', 'r_1000', 'g_1000', 'b_1000']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "res_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit with weights\n",
    "weight_cats = tuple([False])\n",
    "\n",
    "# Model fit with categorical variables\n",
    "cat_cats = (True,False)\n",
    "\n",
    "# Lat/Lon included in model\n",
    "xy_cats = {'no': [],\n",
    "           'both': ['latitude','longitude'],\n",
    "           'lat': ['latitude'],\n",
    "           'lon': ['longitude']}\n",
    "\n",
    "xy_keys = tuple(xy_cats.keys())\n",
    "\n",
    "# Region variables\n",
    "region_cats = {'both': ['region','cluster'],\n",
    "               'reg':  ['region'],\n",
    "               'clust':  ['cluster']}\n",
    "\n",
    "reg_keys = tuple(region_cats.keys())\n",
    "\n",
    "# Elevation Variables\n",
    "ele_cats = {'max_dif':['maxe','dife'],\n",
    "            'all_var':['maxe','dife','elevation','stde'],\n",
    "            'ele_std':['elevation','stde'],\n",
    "            'ele_dif':['elevation','dife'],\n",
    "            'max_std':['maxe','stde'] }\n",
    "\n",
    "ele_keys = tuple(ele_cats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Lag Variables\n",
    "sl_cats = {#'lag100': ['severity_100','logDensity_100','count_100'],\n",
    "           #'lag300': ['severity_300','logDensity_300','count_300'],\n",
    "           #'lag1000': ['severity_1000','logDensity_1000','count_1000'],\n",
    "           'lagNone': []}\n",
    "\n",
    "sl_keys = tuple(sl_cats.keys())\n",
    "\n",
    "# Sat imagery data\n",
    "sat_cats = {'sat500': ['imtype','prop_lake_500','r_500','g_500','b_500'],\n",
    "            'sat1000': ['imtype','prop_lake_1000','r_1000','g_1000','b_1000'],\n",
    "            'sat2500': ['imtype','prop_lake_2500','r_2500','g_2500','b_2500'],\n",
    "            'sat500_1000': ['imtype','prop_lake_500','r_500','g_500','b_500', 'prop_lake_1000','r_1000','g_1000','b_1000'],\n",
    "            'sat500_2500': ['imtype','prop_lake_500','r_500','g_500','b_500', 'prop_lake_2500','r_2500','g_2500','b_2500'],\n",
    "            'sat1000_2500': ['imtype','prop_lake_1000','r_1000','g_1000','b_1000', 'prop_lake_2500','r_2500','g_2500','b_2500']}\n",
    "\n",
    "sat_keys = tuple(sat_cats.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 16:34:32,256]\u001b[0m A new study created in memory with name: no-name-36653462-d5dc-4ad8-98e6-e434f7cf7634\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:34:37,224]\u001b[0m Trial 0 finished with value: 0.922597875556052 and parameters: {'n_estimators': 330, 'max_depth': 8, 'ele_vars': 'all_var', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'cat_type': False, 'sat_set': 'sat500_1000'}. Best is trial 0 with value: 0.922597875556052.\u001b[0m\n",
      "\u001b[33m[W 2023-04-17 16:34:39,733]\u001b[0m Trial 1 failed with parameters: {'n_estimators': 590, 'max_depth': 5, 'ele_vars': 'all_var', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'cat_type': False, 'sat_set': 'sat500_2500'} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Jennah\\AppData\\Local\\Temp\\ipykernel_32396\\4223045919.py\", line 28, in objective_lgb\n",
      "    avg_rmse = rm.met_eval(train_dat,ret=True,weight=param['weight'],cat=param['cat_type'])\n",
      "  File \"c:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py\", line 391, in met_eval\n",
      "    self.fit(train, weight, cat)\n",
      "  File \"c:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py\", line 346, in fit\n",
      "    self.mod.fit(X_dat,y_dat,sample_weight=sw)\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\sklearn.py\", line 895, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\engine.py\", line 292, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\basic.py\", line 3021, in update\n",
      "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-04-17 16:34:39,755]\u001b[0m Trial 1 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m avg_rmse\n\u001b[0;32m     31\u001b[0m study_lgb \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m study_lgb\u001b[39m.\u001b[39;49moptimize(objective_lgb, n_trials\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m) \u001b[39m# 150\u001b[39;00m\n\u001b[0;32m     33\u001b[0m trial_lgb \u001b[39m=\u001b[39m study_lgb\u001b[39m.\u001b[39mbest_trial\n\u001b[0;32m     34\u001b[0m res_results[\u001b[39m'\u001b[39m\u001b[39mlgb\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m trial_lgb\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[9], line 28\u001b[0m, in \u001b[0;36mobjective_lgb\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     19\u001b[0m cv \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sat_cats[param[\u001b[39m'\u001b[39m\u001b[39msat_set\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     20\u001b[0m rm \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mRegMod(ord_vars\u001b[39m=\u001b[39mov,\n\u001b[0;32m     21\u001b[0m                 dum_vars\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m                 dat_vars\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 mod \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mLGBMRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39mround\u001b[39m(param[\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m     27\u001b[0m                                         max_depth\u001b[39m=\u001b[39mparam[\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m---> 28\u001b[0m avg_rmse \u001b[39m=\u001b[39m rm\u001b[39m.\u001b[39;49mmet_eval(train_dat,ret\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,weight\u001b[39m=\u001b[39;49mparam[\u001b[39m'\u001b[39;49m\u001b[39mweight\u001b[39;49m\u001b[39m'\u001b[39;49m],cat\u001b[39m=\u001b[39;49mparam[\u001b[39m'\u001b[39;49m\u001b[39mcat_type\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m avg_rmse\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py:391\u001b[0m, in \u001b[0;36mRegMod.met_eval\u001b[1;34m(self, data, weight, cat, full_train, split_tt, test_size, test_splits, ret, pr)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     train, test \u001b[39m=\u001b[39m split(dc,test_size,s)\n\u001b[1;32m--> 391\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(train, weight, cat)\n\u001b[0;32m    392\u001b[0m test[\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_int(test)\n\u001b[0;32m    393\u001b[0m met_di \u001b[39m=\u001b[39m rmse_region(test,ret\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py:346\u001b[0m, in \u001b[0;36mRegMod.fit\u001b[1;34m(self, X, weight, cat)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmod\u001b[39m.\u001b[39mfit(X_dat, y_dat, sample_weight\u001b[39m=\u001b[39msw)\n\u001b[0;32m    345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmod\u001b[39m.\u001b[39;49mfit(X_dat,y_dat,sample_weight\u001b[39m=\u001b[39;49msw)\n\u001b[0;32m    347\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmod\u001b[39m.\u001b[39mpredict(X_dat)\n\u001b[0;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresids \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(y_dat \u001b[39m-\u001b[39m pred)\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, init_score\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_metric\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m'\u001b[39m, feature_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, categorical_feature\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, init_model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score,\n\u001b[0;32m    896\u001b[0m                 eval_set\u001b[39m=\u001b[39;49meval_set, eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[0;32m    897\u001b[0m                 eval_init_score\u001b[39m=\u001b[39;49meval_init_score, eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[0;32m    898\u001b[0m                 early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds, verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    899\u001b[0m                 categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature, callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[0;32m    900\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[0;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[0;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[0;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[0;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective_lgb(trial):\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 20, 600, 10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"ele_set\": trial.suggest_categorical(\"ele_vars\", ele_keys),\n",
    "        \"xy_set\": trial.suggest_categorical(\"xy_set\", xy_keys),\n",
    "        \"sl_set\": trial.suggest_categorical(\"sl_set\", sl_keys),\n",
    "        \"reg_set\": trial.suggest_categorical(\"reg_set\", reg_keys),\n",
    "        \"weight\": trial.suggest_categorical(\"weight\", weight_cats),\n",
    "        \"cat_type\": trial.suggest_categorical(\"cat_type\", cat_cats),\n",
    "        \"sat_set\": trial.suggest_categorical(\"sat_set\", sat_keys),\n",
    "    }\n",
    "    # Setting the different variables\n",
    "    ov = region_cats[param['reg_set']]\n",
    "    #if 'imtype' in sat_cats[param['sat_set']]:\n",
    "    #    ov.append('imtype')\n",
    "    cv = ele_cats[param['ele_set']] + xy_cats[param['xy_set']]\n",
    "    cv += sl_cats[param['sl_set']]\n",
    "    cv += sat_cats[param['sat_set']]\n",
    "    rm = mod.RegMod(ord_vars=ov,\n",
    "                    dum_vars=None,\n",
    "                    dat_vars=['date'],\n",
    "                    ide_vars=cv,\n",
    "                    weight = 'split_pred',\n",
    "                    y='severity',\n",
    "                    mod = mod.LGBMRegressor(n_estimators=round(param['n_estimators']),\n",
    "                                            max_depth=param['max_depth']))\n",
    "    avg_rmse = rm.met_eval(train_dat,ret=True,weight=param['weight'],cat=param['cat_type'])\n",
    "    return avg_rmse\n",
    "\n",
    "study_lgb = optuna.create_study(direction=\"minimize\")\n",
    "study_lgb.optimize(objective_lgb, n_trials=300) # 150\n",
    "trial_lgb = study_lgb.best_trial\n",
    "res_results['lgb'] = trial_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-15 20:55:31,811]\u001b[0m A new study created in memory with name: no-name-8d4fd44e-4bb6-40ca-9958-b80399873b6b\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:55:49,726]\u001b[0m Trial 0 finished with value: 0.9307713556938809 and parameters: {'n_estimators': 180, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 0 with value: 0.9307713556938809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:55:58,876]\u001b[0m Trial 1 finished with value: 0.9180900243828505 and parameters: {'n_estimators': 80, 'max_depth': 10, 'ele_vars': 'max_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 1 with value: 0.9180900243828505.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:56:08,015]\u001b[0m Trial 2 finished with value: 0.88031152248995 and parameters: {'n_estimators': 190, 'max_depth': 2, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 2 with value: 0.88031152248995.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:56:54,647]\u001b[0m Trial 3 finished with value: 0.8756002304825433 and parameters: {'n_estimators': 370, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 3 with value: 0.8756002304825433.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:57:02,473]\u001b[0m Trial 4 finished with value: 0.8760339327291978 and parameters: {'n_estimators': 80, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 3 with value: 0.8756002304825433.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:57:43,462]\u001b[0m Trial 5 finished with value: 0.8704620824131529 and parameters: {'n_estimators': 530, 'max_depth': 4, 'ele_vars': 'max_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 5 with value: 0.8704620824131529.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:57:50,195]\u001b[0m Trial 6 finished with value: 0.8664887031007946 and parameters: {'n_estimators': 150, 'max_depth': 5, 'ele_vars': 'max_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:57:59,235]\u001b[0m Trial 7 finished with value: 0.8912765292625269 and parameters: {'n_estimators': 150, 'max_depth': 6, 'ele_vars': 'all_var', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:58:12,399]\u001b[0m Trial 8 finished with value: 0.8795117612910429 and parameters: {'n_estimators': 500, 'max_depth': 2, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:59:04,722]\u001b[0m Trial 9 finished with value: 0.9006161534850262 and parameters: {'n_estimators': 580, 'max_depth': 5, 'ele_vars': 'max_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:59:28,250]\u001b[0m Trial 10 finished with value: 0.8825541454822432 and parameters: {'n_estimators': 300, 'max_depth': 4, 'ele_vars': 'ele_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 20:59:58,567]\u001b[0m Trial 11 finished with value: 0.8864417853344511 and parameters: {'n_estimators': 360, 'max_depth': 4, 'ele_vars': 'max_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:00:42,048]\u001b[0m Trial 12 finished with value: 0.8868877930837001 and parameters: {'n_estimators': 470, 'max_depth': 4, 'ele_vars': 'max_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:01:14,314]\u001b[0m Trial 13 finished with value: 0.8851087783199333 and parameters: {'n_estimators': 290, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:01:18,666]\u001b[0m Trial 14 finished with value: 0.9138168015564098 and parameters: {'n_estimators': 30, 'max_depth': 3, 'ele_vars': 'max_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:02:34,951]\u001b[0m Trial 15 finished with value: 0.8919130106229545 and parameters: {'n_estimators': 470, 'max_depth': 8, 'ele_vars': 'all_var', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:02:51,922]\u001b[0m Trial 16 finished with value: 0.8977284873944751 and parameters: {'n_estimators': 600, 'max_depth': 5, 'ele_vars': 'ele_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:02:57,540]\u001b[0m Trial 17 finished with value: 0.8964548935515563 and parameters: {'n_estimators': 240, 'max_depth': 3, 'ele_vars': 'max_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:03:15,459]\u001b[0m Trial 18 finished with value: 0.893878082290452 and parameters: {'n_estimators': 390, 'max_depth': 5, 'ele_vars': 'max_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:03:56,342]\u001b[0m Trial 19 finished with value: 0.9035694142530348 and parameters: {'n_estimators': 550, 'max_depth': 8, 'ele_vars': 'max_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:04:07,144]\u001b[0m Trial 20 finished with value: 0.8869459620182445 and parameters: {'n_estimators': 420, 'max_depth': 3, 'ele_vars': 'all_var', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:04:32,580]\u001b[0m Trial 21 finished with value: 0.8872423504771598 and parameters: {'n_estimators': 350, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:04:55,132]\u001b[0m Trial 22 finished with value: 0.869756018590244 and parameters: {'n_estimators': 270, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:05:16,047]\u001b[0m Trial 23 finished with value: 0.8738406456703481 and parameters: {'n_estimators': 250, 'max_depth': 8, 'ele_vars': 'ele_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:05:23,426]\u001b[0m Trial 24 finished with value: 0.8759022390496541 and parameters: {'n_estimators': 130, 'max_depth': 5, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:05:38,213]\u001b[0m Trial 25 finished with value: 0.8713503605085713 and parameters: {'n_estimators': 240, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:05:51,615]\u001b[0m Trial 26 finished with value: 0.9244281257787355 and parameters: {'n_estimators': 200, 'max_depth': 9, 'ele_vars': 'max_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:03,902]\u001b[0m Trial 27 finished with value: 0.8994054782441581 and parameters: {'n_estimators': 280, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 6 with value: 0.8664887031007946.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:08,206]\u001b[0m Trial 28 finished with value: 0.8580525113425711 and parameters: {'n_estimators': 120, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 28 with value: 0.8580525113425711.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:14,828]\u001b[0m Trial 29 finished with value: 0.8964316592185536 and parameters: {'n_estimators': 120, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 28 with value: 0.8580525113425711.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:17,905]\u001b[0m Trial 30 finished with value: 0.8547986009895652 and parameters: {'n_estimators': 30, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 30 with value: 0.8547986009895652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:20,406]\u001b[0m Trial 31 finished with value: 0.8484802210718746 and parameters: {'n_estimators': 20, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:23,027]\u001b[0m Trial 32 finished with value: 0.8626228911699336 and parameters: {'n_estimators': 20, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:25,569]\u001b[0m Trial 33 finished with value: 0.8496115710914234 and parameters: {'n_estimators': 20, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:32,213]\u001b[0m Trial 34 finished with value: 0.8714834451213678 and parameters: {'n_estimators': 70, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:37,482]\u001b[0m Trial 35 finished with value: 0.8567305097303018 and parameters: {'n_estimators': 60, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:42,930]\u001b[0m Trial 36 finished with value: 0.8566037251217933 and parameters: {'n_estimators': 60, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:47,526]\u001b[0m Trial 37 finished with value: 0.8672568758310005 and parameters: {'n_estimators': 50, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:50,059]\u001b[0m Trial 38 finished with value: 0.855402567792612 and parameters: {'n_estimators': 20, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:06:59,201]\u001b[0m Trial 39 finished with value: 0.8728845401794008 and parameters: {'n_estimators': 100, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:07:18,340]\u001b[0m Trial 40 finished with value: 0.8792666265736285 and parameters: {'n_estimators': 180, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 31 with value: 0.8484802210718746.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:07:20,668]\u001b[0m Trial 41 finished with value: 0.8433903354819321 and parameters: {'n_estimators': 20, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:07:23,320]\u001b[0m Trial 42 finished with value: 0.8571526967840821 and parameters: {'n_estimators': 20, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:07:32,307]\u001b[0m Trial 43 finished with value: 0.8772616477973078 and parameters: {'n_estimators': 100, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:07:36,668]\u001b[0m Trial 44 finished with value: 0.8673167775378955 and parameters: {'n_estimators': 40, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:07:44,201]\u001b[0m Trial 45 finished with value: 0.8744380841212784 and parameters: {'n_estimators': 90, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:07:46,641]\u001b[0m Trial 46 finished with value: 0.8574410737130769 and parameters: {'n_estimators': 20, 'max_depth': 8, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:00,241]\u001b[0m Trial 47 finished with value: 0.9277499917241764 and parameters: {'n_estimators': 160, 'max_depth': 10, 'ele_vars': 'all_var', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:07,288]\u001b[0m Trial 48 finished with value: 0.8704708453450445 and parameters: {'n_estimators': 70, 'max_depth': 9, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:11,456]\u001b[0m Trial 49 finished with value: 0.8734077285607971 and parameters: {'n_estimators': 40, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:17,875]\u001b[0m Trial 50 finished with value: 0.8667433122656408 and parameters: {'n_estimators': 90, 'max_depth': 8, 'ele_vars': 'ele_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:22,447]\u001b[0m Trial 51 finished with value: 0.8593718654838703 and parameters: {'n_estimators': 50, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:28,464]\u001b[0m Trial 52 finished with value: 0.8589942944034931 and parameters: {'n_estimators': 70, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:30,779]\u001b[0m Trial 53 finished with value: 0.8592725934903378 and parameters: {'n_estimators': 20, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:35,994]\u001b[0m Trial 54 finished with value: 0.8748393062394129 and parameters: {'n_estimators': 50, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:44,436]\u001b[0m Trial 55 finished with value: 0.9434805373080989 and parameters: {'n_estimators': 140, 'max_depth': 8, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:08:54,255]\u001b[0m Trial 56 finished with value: 0.9008228863062705 and parameters: {'n_estimators': 110, 'max_depth': 10, 'ele_vars': 'all_var', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:02,344]\u001b[0m Trial 57 finished with value: 0.892617973212699 and parameters: {'n_estimators': 80, 'max_depth': 9, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:06,521]\u001b[0m Trial 58 finished with value: 0.8599008693325407 and parameters: {'n_estimators': 40, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:13,053]\u001b[0m Trial 59 finished with value: 0.8592543902044067 and parameters: {'n_estimators': 60, 'max_depth': 8, 'ele_vars': 'ele_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:37,359]\u001b[0m Trial 60 finished with value: 0.8682499420423724 and parameters: {'n_estimators': 330, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:42,576]\u001b[0m Trial 61 finished with value: 0.8610643200345921 and parameters: {'n_estimators': 60, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:45,119]\u001b[0m Trial 62 finished with value: 0.860996080404799 and parameters: {'n_estimators': 20, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:52,488]\u001b[0m Trial 63 finished with value: 0.8682761329517895 and parameters: {'n_estimators': 80, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:09:56,236]\u001b[0m Trial 64 finished with value: 0.8585943735951231 and parameters: {'n_estimators': 40, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:10:14,054]\u001b[0m Trial 65 finished with value: 0.8857262414787168 and parameters: {'n_estimators': 210, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:10:18,322]\u001b[0m Trial 66 finished with value: 0.9036123303218124 and parameters: {'n_estimators': 60, 'max_depth': 8, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:10:27,958]\u001b[0m Trial 67 finished with value: 0.9195409162962722 and parameters: {'n_estimators': 110, 'max_depth': 10, 'ele_vars': 'all_var', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:10:36,790]\u001b[0m Trial 68 finished with value: 0.8570084180572671 and parameters: {'n_estimators': 150, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:10:39,740]\u001b[0m Trial 69 finished with value: 0.8609891136083763 and parameters: {'n_estimators': 30, 'max_depth': 9, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:10:46,232]\u001b[0m Trial 70 finished with value: 0.8586868155129362 and parameters: {'n_estimators': 90, 'max_depth': 8, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:10:58,948]\u001b[0m Trial 71 finished with value: 0.8666538933002936 and parameters: {'n_estimators': 160, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:11:03,176]\u001b[0m Trial 72 finished with value: 0.85622027572969 and parameters: {'n_estimators': 40, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:11:07,568]\u001b[0m Trial 73 finished with value: 0.8621012130584225 and parameters: {'n_estimators': 40, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:11:13,317]\u001b[0m Trial 74 finished with value: 0.8741234188249252 and parameters: {'n_estimators': 60, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:11:16,339]\u001b[0m Trial 75 finished with value: 0.8592874760416741 and parameters: {'n_estimators': 20, 'max_depth': 10, 'ele_vars': 'ele_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:11:24,562]\u001b[0m Trial 76 finished with value: 0.862733822182849 and parameters: {'n_estimators': 80, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:11:28,826]\u001b[0m Trial 77 finished with value: 0.8592524106244446 and parameters: {'n_estimators': 40, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:11:31,600]\u001b[0m Trial 78 finished with value: 0.94071643143632 and parameters: {'n_estimators': 130, 'max_depth': 2, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:01,120]\u001b[0m Trial 79 finished with value: 0.8932828506677595 and parameters: {'n_estimators': 450, 'max_depth': 9, 'ele_vars': 'ele_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:04,714]\u001b[0m Trial 80 finished with value: 0.8644042019528524 and parameters: {'n_estimators': 30, 'max_depth': 10, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 41 with value: 0.8433903354819321.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:09,356]\u001b[0m Trial 81 finished with value: 0.8420298093069285 and parameters: {'n_estimators': 60, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 81 with value: 0.8420298093069285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:13,495]\u001b[0m Trial 82 finished with value: 0.8301078787963169 and parameters: {'n_estimators': 60, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:19,746]\u001b[0m Trial 83 finished with value: 0.85424091971342 and parameters: {'n_estimators': 100, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:25,136]\u001b[0m Trial 84 finished with value: 0.855663679926281 and parameters: {'n_estimators': 100, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:30,957]\u001b[0m Trial 85 finished with value: 0.8627593978750095 and parameters: {'n_estimators': 110, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:38,318]\u001b[0m Trial 86 finished with value: 0.9159198307420624 and parameters: {'n_estimators': 100, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:42,346]\u001b[0m Trial 87 finished with value: 0.8468613506111629 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:48,040]\u001b[0m Trial 88 finished with value: 0.8610726898224945 and parameters: {'n_estimators': 80, 'max_depth': 7, 'ele_vars': 'all_var', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:49,898]\u001b[0m Trial 89 finished with value: 0.8600993884999779 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:53,216]\u001b[0m Trial 90 finished with value: 0.865124034183338 and parameters: {'n_estimators': 70, 'max_depth': 5, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:56,506]\u001b[0m Trial 91 finished with value: 0.850956751351385 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:12:59,593]\u001b[0m Trial 92 finished with value: 0.8339091271328553 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:02,727]\u001b[0m Trial 93 finished with value: 0.8498076481285974 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:06,309]\u001b[0m Trial 94 finished with value: 0.8422002995104423 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:09,382]\u001b[0m Trial 95 finished with value: 0.8353456995139876 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:12,861]\u001b[0m Trial 96 finished with value: 0.845087238716079 and parameters: {'n_estimators': 70, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:16,216]\u001b[0m Trial 97 finished with value: 0.8473893447742638 and parameters: {'n_estimators': 70, 'max_depth': 5, 'ele_vars': 'ele_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:21,080]\u001b[0m Trial 98 finished with value: 0.8768151775838386 and parameters: {'n_estimators': 120, 'max_depth': 5, 'ele_vars': 'ele_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:25,557]\u001b[0m Trial 99 finished with value: 0.8628492779195243 and parameters: {'n_estimators': 130, 'max_depth': 4, 'ele_vars': 'ele_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:28,734]\u001b[0m Trial 100 finished with value: 0.8620268717739179 and parameters: {'n_estimators': 70, 'max_depth': 5, 'ele_vars': 'ele_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:32,600]\u001b[0m Trial 101 finished with value: 0.8665204339233892 and parameters: {'n_estimators': 90, 'max_depth': 5, 'ele_vars': 'ele_dif', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:36,606]\u001b[0m Trial 102 finished with value: 0.84738895800896 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:40,522]\u001b[0m Trial 103 finished with value: 0.8666283759724858 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:13:43,992]\u001b[0m Trial 104 finished with value: 0.8573351117019952 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:04,108]\u001b[0m Trial 105 finished with value: 0.8723738132686151 and parameters: {'n_estimators': 520, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:06,465]\u001b[0m Trial 106 finished with value: 0.9046696915932717 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_dif', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:10,181]\u001b[0m Trial 107 finished with value: 0.8434920408502122 and parameters: {'n_estimators': 80, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:13,072]\u001b[0m Trial 108 finished with value: 0.8686060849702057 and parameters: {'n_estimators': 80, 'max_depth': 3, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:16,430]\u001b[0m Trial 109 finished with value: 0.9175255328594792 and parameters: {'n_estimators': 90, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:19,769]\u001b[0m Trial 110 finished with value: 0.8573815735231222 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:22,772]\u001b[0m Trial 111 finished with value: 0.8468584642140117 and parameters: {'n_estimators': 50, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:25,645]\u001b[0m Trial 112 finished with value: 0.8464476718358706 and parameters: {'n_estimators': 50, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:28,557]\u001b[0m Trial 113 finished with value: 0.8481536657170249 and parameters: {'n_estimators': 50, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:31,590]\u001b[0m Trial 114 finished with value: 0.8367185783922974 and parameters: {'n_estimators': 60, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:33,432]\u001b[0m Trial 115 finished with value: 0.8456589543780885 and parameters: {'n_estimators': 30, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:35,347]\u001b[0m Trial 116 finished with value: 0.8643742424838349 and parameters: {'n_estimators': 30, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:37,415]\u001b[0m Trial 117 finished with value: 0.8580404749220392 and parameters: {'n_estimators': 40, 'max_depth': 3, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:39,901]\u001b[0m Trial 118 finished with value: 0.8541356157092739 and parameters: {'n_estimators': 50, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:56,087]\u001b[0m Trial 119 finished with value: 0.8632928890804665 and parameters: {'n_estimators': 390, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:14:58,841]\u001b[0m Trial 120 finished with value: 0.8506958057546111 and parameters: {'n_estimators': 60, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:04,915]\u001b[0m Trial 121 finished with value: 0.8629071073347372 and parameters: {'n_estimators': 90, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:06,711]\u001b[0m Trial 122 finished with value: 0.8639496133803106 and parameters: {'n_estimators': 30, 'max_depth': 3, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:10,766]\u001b[0m Trial 123 finished with value: 0.8449936641595353 and parameters: {'n_estimators': 80, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:15,979]\u001b[0m Trial 124 finished with value: 0.8682627156857855 and parameters: {'n_estimators': 110, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:18,169]\u001b[0m Trial 125 finished with value: 0.8425324123095155 and parameters: {'n_estimators': 40, 'max_depth': 4, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:21,787]\u001b[0m Trial 126 finished with value: 0.8445833595372889 and parameters: {'n_estimators': 80, 'max_depth': 4, 'ele_vars': 'all_var', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:24,455]\u001b[0m Trial 127 finished with value: 0.8544308646477046 and parameters: {'n_estimators': 40, 'max_depth': 4, 'ele_vars': 'all_var', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:28,843]\u001b[0m Trial 128 finished with value: 0.8655857037514112 and parameters: {'n_estimators': 80, 'max_depth': 4, 'ele_vars': 'all_var', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:37,431]\u001b[0m Trial 129 finished with value: 0.869297799716471 and parameters: {'n_estimators': 220, 'max_depth': 4, 'ele_vars': 'all_var', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:39,739]\u001b[0m Trial 130 finished with value: 0.8537289419697632 and parameters: {'n_estimators': 30, 'max_depth': 4, 'ele_vars': 'all_var', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:42,278]\u001b[0m Trial 131 finished with value: 0.8545690097407086 and parameters: {'n_estimators': 60, 'max_depth': 3, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:45,041]\u001b[0m Trial 132 finished with value: 0.8437188050696942 and parameters: {'n_estimators': 60, 'max_depth': 4, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:48,660]\u001b[0m Trial 133 finished with value: 0.852036732810744 and parameters: {'n_estimators': 90, 'max_depth': 4, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:51,390]\u001b[0m Trial 134 finished with value: 0.8556696699069901 and parameters: {'n_estimators': 60, 'max_depth': 4, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:54,620]\u001b[0m Trial 135 finished with value: 0.8610548146595836 and parameters: {'n_estimators': 100, 'max_depth': 3, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:57,947]\u001b[0m Trial 136 finished with value: 0.8526173975102397 and parameters: {'n_estimators': 80, 'max_depth': 4, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:15:59,461]\u001b[0m Trial 137 finished with value: 0.9037012476105437 and parameters: {'n_estimators': 20, 'max_depth': 4, 'ele_vars': 'all_var', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:01,601]\u001b[0m Trial 138 finished with value: 0.8690700753617907 and parameters: {'n_estimators': 40, 'max_depth': 4, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:04,587]\u001b[0m Trial 139 finished with value: 0.8670112412309123 and parameters: {'n_estimators': 80, 'max_depth': 3, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:11,599]\u001b[0m Trial 140 finished with value: 0.8684149567969139 and parameters: {'n_estimators': 110, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:14,932]\u001b[0m Trial 141 finished with value: 0.8514177398416182 and parameters: {'n_estimators': 60, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:17,574]\u001b[0m Trial 142 finished with value: 0.8429278365534298 and parameters: {'n_estimators': 40, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:20,139]\u001b[0m Trial 143 finished with value: 0.8423411427495168 and parameters: {'n_estimators': 40, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:33,271]\u001b[0m Trial 144 finished with value: 0.8649607661285799 and parameters: {'n_estimators': 310, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:36,614]\u001b[0m Trial 145 finished with value: 0.9034304439606979 and parameters: {'n_estimators': 70, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:39,655]\u001b[0m Trial 146 finished with value: 0.8570923629648236 and parameters: {'n_estimators': 50, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:43,011]\u001b[0m Trial 147 finished with value: 0.8393925633806564 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:45,804]\u001b[0m Trial 148 finished with value: 0.8532821810806505 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:47,942]\u001b[0m Trial 149 finished with value: 0.8402090126152585 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:50,678]\u001b[0m Trial 150 finished with value: 0.8381207182313668 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:52,875]\u001b[0m Trial 151 finished with value: 0.8402722597429382 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:55,024]\u001b[0m Trial 152 finished with value: 0.8475618756716783 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:16:58,546]\u001b[0m Trial 153 finished with value: 0.8467823269866035 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:00,886]\u001b[0m Trial 154 finished with value: 0.8559786671282064 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:04,737]\u001b[0m Trial 155 finished with value: 0.8587038619350116 and parameters: {'n_estimators': 40, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:07,081]\u001b[0m Trial 156 finished with value: 0.8473657998482477 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:10,453]\u001b[0m Trial 157 finished with value: 0.8412717771010791 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:13,908]\u001b[0m Trial 158 finished with value: 0.8416172817591931 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:17,371]\u001b[0m Trial 159 finished with value: 0.8415716213578701 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:20,244]\u001b[0m Trial 160 finished with value: 0.839678337940418 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:23,247]\u001b[0m Trial 161 finished with value: 0.850465669235853 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:26,731]\u001b[0m Trial 162 finished with value: 0.8464329724893556 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:31,646]\u001b[0m Trial 163 finished with value: 0.8544941703516173 and parameters: {'n_estimators': 50, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:34,525]\u001b[0m Trial 164 finished with value: 0.8461168388127668 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:38,531]\u001b[0m Trial 165 finished with value: 0.8594631835559585 and parameters: {'n_estimators': 40, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:40,797]\u001b[0m Trial 166 finished with value: 0.8425783798216354 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:43,122]\u001b[0m Trial 167 finished with value: 0.8715602444443288 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:47,193]\u001b[0m Trial 168 finished with value: 0.850823564430223 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:49,488]\u001b[0m Trial 169 finished with value: 0.8488654357670624 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:52,566]\u001b[0m Trial 170 finished with value: 0.8393162395618706 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:55,410]\u001b[0m Trial 171 finished with value: 0.8459635134785367 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:17:59,669]\u001b[0m Trial 172 finished with value: 0.857980046609382 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:02,559]\u001b[0m Trial 173 finished with value: 0.8366216314640511 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:06,453]\u001b[0m Trial 174 finished with value: 0.8404570248026424 and parameters: {'n_estimators': 40, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:11,870]\u001b[0m Trial 175 finished with value: 0.8577301151313792 and parameters: {'n_estimators': 60, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:14,891]\u001b[0m Trial 176 finished with value: 0.8880091499983168 and parameters: {'n_estimators': 30, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:19,560]\u001b[0m Trial 177 finished with value: 0.8471257211597308 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:23,844]\u001b[0m Trial 178 finished with value: 0.8370904171701318 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:27,944]\u001b[0m Trial 179 finished with value: 0.84392291126257 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:32,826]\u001b[0m Trial 180 finished with value: 0.8576107156991025 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:36,307]\u001b[0m Trial 181 finished with value: 0.8408481068357936 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:39,728]\u001b[0m Trial 182 finished with value: 0.8461782423488146 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:42,928]\u001b[0m Trial 183 finished with value: 0.8516790619277884 and parameters: {'n_estimators': 30, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:47,071]\u001b[0m Trial 184 finished with value: 0.8490854806934454 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:18:49,907]\u001b[0m Trial 185 finished with value: 0.8531273591404702 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:19:06,662]\u001b[0m Trial 186 finished with value: 0.8727988226572132 and parameters: {'n_estimators': 260, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:19:12,645]\u001b[0m Trial 187 finished with value: 0.8571329327229844 and parameters: {'n_estimators': 70, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:19:50,631]\u001b[0m Trial 188 finished with value: 0.8873110730342505 and parameters: {'n_estimators': 560, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:19:52,873]\u001b[0m Trial 189 finished with value: 0.8531457487263083 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:19:56,395]\u001b[0m Trial 190 finished with value: 0.8569120009549852 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:01,138]\u001b[0m Trial 191 finished with value: 0.8509084889773721 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:04,703]\u001b[0m Trial 192 finished with value: 0.852004532453425 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:10,086]\u001b[0m Trial 193 finished with value: 0.8491145614619052 and parameters: {'n_estimators': 60, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:12,951]\u001b[0m Trial 194 finished with value: 0.8555681629091136 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:15,401]\u001b[0m Trial 195 finished with value: 0.84330592388997 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:18,903]\u001b[0m Trial 196 finished with value: 0.8441632103526648 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:23,820]\u001b[0m Trial 197 finished with value: 0.8451939013327243 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:28,343]\u001b[0m Trial 198 finished with value: 0.8570410434168492 and parameters: {'n_estimators': 50, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:31,420]\u001b[0m Trial 199 finished with value: 0.8493179843756404 and parameters: {'n_estimators': 30, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:37,025]\u001b[0m Trial 200 finished with value: 0.8658416591709152 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:40,593]\u001b[0m Trial 201 finished with value: 0.8420007975213475 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:44,246]\u001b[0m Trial 202 finished with value: 0.8385714166160158 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:46,508]\u001b[0m Trial 203 finished with value: 0.8415980136751087 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:48,953]\u001b[0m Trial 204 finished with value: 0.8456871488192881 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:50,446]\u001b[0m Trial 205 finished with value: 0.9266633096669669 and parameters: {'n_estimators': 20, 'max_depth': 2, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:54,580]\u001b[0m Trial 206 finished with value: 0.8637370905012366 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:20:58,018]\u001b[0m Trial 207 finished with value: 0.8446381420905429 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:01,026]\u001b[0m Trial 208 finished with value: 0.853623960086629 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:04,177]\u001b[0m Trial 209 finished with value: 0.8491128744598981 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:06,869]\u001b[0m Trial 210 finished with value: 0.8816783893901314 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:11,144]\u001b[0m Trial 211 finished with value: 0.8547315830812623 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:15,843]\u001b[0m Trial 212 finished with value: 0.8464943215762064 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:18,157]\u001b[0m Trial 213 finished with value: 0.8458394117568007 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:21,740]\u001b[0m Trial 214 finished with value: 0.8468484001920558 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:27,054]\u001b[0m Trial 215 finished with value: 0.8540753771410345 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:31,722]\u001b[0m Trial 216 finished with value: 0.8431319866053141 and parameters: {'n_estimators': 50, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:34,142]\u001b[0m Trial 217 finished with value: 0.854242571281806 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:38,814]\u001b[0m Trial 218 finished with value: 0.8683572221921846 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:41,881]\u001b[0m Trial 219 finished with value: 0.8372254721159035 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:44,750]\u001b[0m Trial 220 finished with value: 0.8557066223894416 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:48,219]\u001b[0m Trial 221 finished with value: 0.8444110293192446 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:52,565]\u001b[0m Trial 222 finished with value: 0.8472180367271944 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:55,439]\u001b[0m Trial 223 finished with value: 0.8501173245794134 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:21:59,010]\u001b[0m Trial 224 finished with value: 0.8370638204191986 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:01,918]\u001b[0m Trial 225 finished with value: 0.8527842216080549 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:05,565]\u001b[0m Trial 226 finished with value: 0.857316396510176 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:08,355]\u001b[0m Trial 227 finished with value: 0.85329995067504 and parameters: {'n_estimators': 20, 'max_depth': 8, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:12,468]\u001b[0m Trial 228 finished with value: 0.8502472675865302 and parameters: {'n_estimators': 40, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:14,707]\u001b[0m Trial 229 finished with value: 0.8410221846369123 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:16,992]\u001b[0m Trial 230 finished with value: 0.8584319804901248 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:19,866]\u001b[0m Trial 231 finished with value: 0.8398165575860229 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:22,752]\u001b[0m Trial 232 finished with value: 0.8415476939446871 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:25,298]\u001b[0m Trial 233 finished with value: 0.8507642331896073 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:28,395]\u001b[0m Trial 234 finished with value: 0.85144499260229 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:22:31,512]\u001b[0m Trial 235 finished with value: 0.854104557713173 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:01,148]\u001b[0m Trial 236 finished with value: 0.8728951798457179 and parameters: {'n_estimators': 480, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:03,121]\u001b[0m Trial 237 finished with value: 0.8430527516346974 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:06,817]\u001b[0m Trial 238 finished with value: 0.8464087339683071 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:10,650]\u001b[0m Trial 239 finished with value: 0.8611490216545059 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:13,489]\u001b[0m Trial 240 finished with value: 0.8369770930643814 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:16,240]\u001b[0m Trial 241 finished with value: 0.8521310162027367 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:19,088]\u001b[0m Trial 242 finished with value: 0.8391142941911329 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:21,202]\u001b[0m Trial 243 finished with value: 0.853949861406285 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:23,942]\u001b[0m Trial 244 finished with value: 0.8429579852400015 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:26,209]\u001b[0m Trial 245 finished with value: 0.8584742192877343 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:29,487]\u001b[0m Trial 246 finished with value: 0.8524581867354536 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:33,233]\u001b[0m Trial 247 finished with value: 0.8642311805481325 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:35,948]\u001b[0m Trial 248 finished with value: 0.8545064405675822 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:40,026]\u001b[0m Trial 249 finished with value: 0.8594903675169379 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:41,867]\u001b[0m Trial 250 finished with value: 0.8384869854972505 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:44,702]\u001b[0m Trial 251 finished with value: 0.846206728413814 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:47,447]\u001b[0m Trial 252 finished with value: 0.8456042939368549 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:49,277]\u001b[0m Trial 253 finished with value: 0.8382715870354251 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:50,982]\u001b[0m Trial 254 finished with value: 0.8900507745211584 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:53,276]\u001b[0m Trial 255 finished with value: 0.8549069435133253 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:55,505]\u001b[0m Trial 256 finished with value: 0.8477858101031016 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:23:58,705]\u001b[0m Trial 257 finished with value: 0.8464043396067602 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:24:01,121]\u001b[0m Trial 258 finished with value: 0.8437786075517215 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:24:03,080]\u001b[0m Trial 259 finished with value: 0.8417734335507359 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:24:06,798]\u001b[0m Trial 260 finished with value: 0.853295583740856 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:24:18,516]\u001b[0m Trial 261 finished with value: 0.8711522633922926 and parameters: {'n_estimators': 180, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:24:42,493]\u001b[0m Trial 262 finished with value: 0.8846088489076148 and parameters: {'n_estimators': 370, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:24:44,806]\u001b[0m Trial 263 finished with value: 0.839362177766489 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:13,489]\u001b[0m Trial 264 finished with value: 0.8981627737223328 and parameters: {'n_estimators': 600, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:16,788]\u001b[0m Trial 265 finished with value: 0.8569675587627124 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:19,490]\u001b[0m Trial 266 finished with value: 0.8471969513654667 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:23,246]\u001b[0m Trial 267 finished with value: 0.8463905605698857 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:25,689]\u001b[0m Trial 268 finished with value: 0.8632543499290415 and parameters: {'n_estimators': 30, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:27,706]\u001b[0m Trial 269 finished with value: 0.8503074226251577 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:30,925]\u001b[0m Trial 270 finished with value: 0.8358365761018594 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:25:35,806]\u001b[0m Trial 271 finished with value: 0.8551077078538526 and parameters: {'n_estimators': 50, 'max_depth': 8, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:00,363]\u001b[0m Trial 272 finished with value: 0.9267402383179025 and parameters: {'n_estimators': 430, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:02,692]\u001b[0m Trial 273 finished with value: 0.8506274820353384 and parameters: {'n_estimators': 20, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:06,028]\u001b[0m Trial 274 finished with value: 0.8471382287118793 and parameters: {'n_estimators': 40, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:10,975]\u001b[0m Trial 275 finished with value: 0.8517989635472929 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:13,386]\u001b[0m Trial 276 finished with value: 0.8558110196242483 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:18,879]\u001b[0m Trial 277 finished with value: 0.8488757998145999 and parameters: {'n_estimators': 60, 'max_depth': 7, 'ele_vars': 'all_var', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:21,801]\u001b[0m Trial 278 finished with value: 0.8497267397029926 and parameters: {'n_estimators': 40, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:23,732]\u001b[0m Trial 279 finished with value: 0.9208797752163514 and parameters: {'n_estimators': 20, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:27,648]\u001b[0m Trial 280 finished with value: 0.8443557400702059 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:45,181]\u001b[0m Trial 281 finished with value: 0.8780812955478323 and parameters: {'n_estimators': 290, 'max_depth': 6, 'ele_vars': 'max_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:48,226]\u001b[0m Trial 282 finished with value: 0.8476645884942842 and parameters: {'n_estimators': 30, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:51,504]\u001b[0m Trial 283 finished with value: 0.8370535472342592 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:55,620]\u001b[0m Trial 284 finished with value: 0.8398735103029933 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:26:59,192]\u001b[0m Trial 285 finished with value: 0.8428582964813257 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:03,296]\u001b[0m Trial 286 finished with value: 0.8570046567718819 and parameters: {'n_estimators': 70, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:06,823]\u001b[0m Trial 287 finished with value: 0.8641060340335747 and parameters: {'n_estimators': 70, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:18,130]\u001b[0m Trial 288 finished with value: 0.8750372732479216 and parameters: {'n_estimators': 230, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:21,300]\u001b[0m Trial 289 finished with value: 0.8418236568830417 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:24,587]\u001b[0m Trial 290 finished with value: 0.8437620321248668 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:28,168]\u001b[0m Trial 291 finished with value: 0.8463666395532163 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:31,374]\u001b[0m Trial 292 finished with value: 0.8498199933309841 and parameters: {'n_estimators': 40, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:33,602]\u001b[0m Trial 293 finished with value: 0.8500555847894343 and parameters: {'n_estimators': 30, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:36,908]\u001b[0m Trial 294 finished with value: 0.8557468111308433 and parameters: {'n_estimators': 50, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:41,504]\u001b[0m Trial 295 finished with value: 0.863048423904751 and parameters: {'n_estimators': 60, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_1000'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:44,420]\u001b[0m Trial 296 finished with value: 0.8594740838037034 and parameters: {'n_estimators': 40, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'lon', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:45,943]\u001b[0m Trial 297 finished with value: 0.9315468665406252 and parameters: {'n_estimators': 30, 'max_depth': 2, 'ele_vars': 'ele_std', 'xy_set': 'lat', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat500_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:50,599]\u001b[0m Trial 298 finished with value: 0.860358912201718 and parameters: {'n_estimators': 80, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n",
      "\u001b[32m[I 2023-04-15 21:27:52,650]\u001b[0m Trial 299 finished with value: 0.8546345422456305 and parameters: {'n_estimators': 20, 'max_depth': 5, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'sat_set': 'sat1000_2500'}. Best is trial 82 with value: 0.8301078787963169.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 20, 600, 10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"ele_set\": trial.suggest_categorical(\"ele_vars\", ele_keys),\n",
    "        \"xy_set\": trial.suggest_categorical(\"xy_set\", xy_keys),\n",
    "        \"sl_set\": trial.suggest_categorical(\"sl_set\", sl_keys),\n",
    "        \"reg_set\": trial.suggest_categorical(\"reg_set\", reg_keys),\n",
    "        \"weight\": trial.suggest_categorical(\"weight\", weight_cats),\n",
    "        \"sat_set\": trial.suggest_categorical(\"sat_set\", sat_keys),\n",
    "    }\n",
    "    # Setting the different variables\n",
    "    ov = region_cats[param['reg_set']]\n",
    "    #if 'imtype' in sat_cats[param['sat_set']]:\n",
    "    #    ov.append('imtype')\n",
    "    cv = ele_cats[param['ele_set']] + xy_cats[param['xy_set']]\n",
    "    cv += sl_cats[param['sl_set']]\n",
    "    cv += sat_cats[param['sat_set']]\n",
    "    rm = mod.RegMod(ord_vars=ov,\n",
    "                    dum_vars=None,\n",
    "                    dat_vars=['date'],\n",
    "                    ide_vars=cv,\n",
    "                    weight = 'split_pred',\n",
    "                    y='severity',\n",
    "                    mod = mod.XGBRegressor(n_estimators=round(param['n_estimators']),\n",
    "                                           max_depth=param['max_depth'])\n",
    "                )\n",
    "    avg_rmse = rm.met_eval(train_dat,ret=True,weight=param['weight'])\n",
    "    return avg_rmse\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=300)\n",
    "trial_xgb = study_xgb.best_trial\n",
    "res_results['xgb'] = trial_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 16:34:56,794]\u001b[0m A new study created in memory with name: no-name-40b64eef-a8dc-4cc5-9e70-765ea88cf4a5\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:35:00,489]\u001b[0m Trial 0 finished with value: 0.9029108304147316 and parameters: {'n_estimators': 200, 'max_depth': 4, 'ele_vars': 'max_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'clust', 'weight': False, 'cat_type': False, 'sat_set': 'sat500_2500'}. Best is trial 0 with value: 0.9029108304147316.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:35:02,688]\u001b[0m Trial 1 finished with value: 0.9063912690991474 and parameters: {'n_estimators': 170, 'max_depth': 2, 'ele_vars': 'max_dif', 'xy_set': 'no', 'sl_set': 'lagNone', 'reg_set': 'both', 'weight': False, 'cat_type': False, 'sat_set': 'sat2500'}. Best is trial 0 with value: 0.9029108304147316.\u001b[0m\n",
      "\u001b[33m[W 2023-04-17 16:35:10,768]\u001b[0m Trial 2 failed with parameters: {'n_estimators': 330, 'max_depth': 7, 'ele_vars': 'ele_dif', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'cat_type': True, 'sat_set': 'sat500_1000'} because of the following error: KeyboardInterrupt('').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Jennah\\AppData\\Local\\Temp\\ipykernel_32396\\79099285.py\", line 31, in objective_cat\n",
      "    avg_rmse = rm.met_eval(train_dat,ret=True,weight=param['weight'],cat=param['cat_type'])\n",
      "  File \"c:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py\", line 391, in met_eval\n",
      "    self.fit(train, weight, cat)\n",
      "  File \"c:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py\", line 338, in fit\n",
      "    self.mod.fit(X_dat,y_dat,sample_weight=sw,cat_features=ci)\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\catboost\\core.py\", line 5730, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\catboost\\core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\catboost\\core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-04-17 16:35:10,773]\u001b[0m Trial 2 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m avg_rmse\n\u001b[0;32m     34\u001b[0m study_cat \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m study_cat\u001b[39m.\u001b[39;49moptimize(objective_cat, n_trials\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)\n\u001b[0;32m     36\u001b[0m trial_cat \u001b[39m=\u001b[39m study_cat\u001b[39m.\u001b[39mbest_trial\n\u001b[0;32m     37\u001b[0m res_results[\u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m trial_cat\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m, in \u001b[0;36mobjective_cat\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     19\u001b[0m cv \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sat_cats[param[\u001b[39m'\u001b[39m\u001b[39msat_set\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     20\u001b[0m rm \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mRegMod(ord_vars\u001b[39m=\u001b[39mov,\n\u001b[0;32m     21\u001b[0m                 dum_vars\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m                 dat_vars\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m                                             verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m             )\n\u001b[1;32m---> 31\u001b[0m avg_rmse \u001b[39m=\u001b[39m rm\u001b[39m.\u001b[39;49mmet_eval(train_dat,ret\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,weight\u001b[39m=\u001b[39;49mparam[\u001b[39m'\u001b[39;49m\u001b[39mweight\u001b[39;49m\u001b[39m'\u001b[39;49m],cat\u001b[39m=\u001b[39;49mparam[\u001b[39m'\u001b[39;49m\u001b[39mcat_type\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m avg_rmse\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py:391\u001b[0m, in \u001b[0;36mRegMod.met_eval\u001b[1;34m(self, data, weight, cat, full_train, split_tt, test_size, test_splits, ret, pr)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     train, test \u001b[39m=\u001b[39m split(dc,test_size,s)\n\u001b[1;32m--> 391\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(train, weight, cat)\n\u001b[0;32m    392\u001b[0m test[\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_int(test)\n\u001b[0;32m    393\u001b[0m met_di \u001b[39m=\u001b[39m rmse_region(test,ret\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\Desktop\\Code\\rds_project\\algaebloom\\src\\mod.py:338\u001b[0m, in \u001b[0;36mRegMod.fit\u001b[1;34m(self, X, weight, cat)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    337\u001b[0m         ci \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmod\u001b[39m.\u001b[39;49mfit(X_dat,y_dat,sample_weight\u001b[39m=\u001b[39;49msw,cat_features\u001b[39m=\u001b[39;49mci)\n\u001b[0;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_cat \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmod) \u001b[39m==\u001b[39m LGBMRegressor) \u001b[39m&\u001b[39m cat:\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\catboost\\core.py:5730\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5728\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\catboost\\core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2356\u001b[0m         train_pool,\n\u001b[0;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2358\u001b[0m         params,\n\u001b[0;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2361\u001b[0m     )\n\u001b[0;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\Jennah\\anaconda3\\envs\\bloom\\lib\\site-packages\\catboost\\core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective_cat(trial):\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 20, 600, 10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"ele_set\": trial.suggest_categorical(\"ele_vars\", ele_keys),\n",
    "        \"xy_set\": trial.suggest_categorical(\"xy_set\", xy_keys),\n",
    "        \"sl_set\": trial.suggest_categorical(\"sl_set\", sl_keys),\n",
    "        \"reg_set\": trial.suggest_categorical(\"reg_set\", reg_keys),\n",
    "        \"weight\": trial.suggest_categorical(\"weight\", weight_cats),\n",
    "        \"cat_type\": trial.suggest_categorical(\"cat_type\", cat_cats),\n",
    "        \"sat_set\": trial.suggest_categorical(\"sat_set\", sat_keys),\n",
    "    }\n",
    "    # Setting the different variables\n",
    "    ov = region_cats[param['reg_set']]\n",
    "    #if 'imtype' in sat_cats[param['sat_set']]:\n",
    "    #    ov.append('imtype')\n",
    "    cv = ele_cats[param['ele_set']] + xy_cats[param['xy_set']]\n",
    "    cv += sl_cats[param['sl_set']]\n",
    "    cv += sat_cats[param['sat_set']]\n",
    "    rm = mod.RegMod(ord_vars=ov,\n",
    "                    dum_vars=None,\n",
    "                    dat_vars=['date'],\n",
    "                    ide_vars=cv,\n",
    "                    weight = 'split_pred',\n",
    "                    y='severity',\n",
    "                    mod = mod.CatBoostRegressor(iterations=round(param['n_estimators']),\n",
    "                                                depth=param['max_depth'],\n",
    "                                                allow_writing_files=False,\n",
    "                                                verbose=False)\n",
    "                )\n",
    "    avg_rmse = rm.met_eval(train_dat,ret=True,weight=param['weight'],cat=param['cat_type'])\n",
    "    return avg_rmse\n",
    "\n",
    "study_cat = optuna.create_study(direction=\"minimize\")\n",
    "study_cat.optimize(objective_cat, n_trials=300)\n",
    "trial_cat = study_cat.best_trial\n",
    "res_results['cat'] = trial_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Average RMSE LightBoost 0.8202049012609962\n",
      "Best Params\n",
      "{'n_estimators': 250, 'max_depth': 6, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'cat_type': True, 'sat_set': 'sat2500'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Average RMSE LightBoost {trial_lgb.value}\")\n",
    "# Best Average RMSE LightBoost 0.8202049012609962\n",
    "print(\"Best Params\")\n",
    "print(trial_lgb.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Average RMSE XGBoost 0.8301078787963169\n",
      "Best Params\n",
      "{'n_estimators': 60, 'max_depth': 7, 'ele_vars': 'ele_std', 'xy_set': 'both', 'sl_set': 'lagNone', 'reg_set': 'reg', 'weight': False, 'sat_set': 'sat2500'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 220,\n",
       " 'max_depth': 9,\n",
       " 'ele_vars': 'ele_std',\n",
       " 'xy_set': 'both',\n",
       " 'reg_set': 'both',\n",
       " 'weight': True}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Best Average RMSE XGBoost {trial_xgb.value}\")\n",
    "# Best Average RMSE XGBoost 0.7703229517195069\n",
    "print(\"Best Params\")\n",
    "print(trial_xgb.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Average RMSE CatBoost {trial_cat.value}\")\n",
    "#Best Average RMSE CatBoost 0.7526218612441193\n",
    "print(\"Best Params\")\n",
    "print(trial_cat.params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8429004962271186"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lig = mod.RegMod(ord_vars=region_cats['reg'],\n",
    "                dat_vars=['date'],\n",
    "                ide_vars=ele_cats['ele_std'] + xy_cats['both'] + sl_cats['lagNone'] + sat_2500,\n",
    "                y='severity',\n",
    "                mod = mod.LGBMRegressor(n_estimators=trial_lgb.params['n_estimators'], \n",
    "                                        max_depth=trial_lgb.params['max_depth'])\n",
    "                )\n",
    "lig.fit(train_dat,weight=trial_lgb.params['weight'],cat=trial_lgb.params['cat_type'])\n",
    "lig.met_eval(train_dat,ret=True,weight=trial_lgb.params['weight'],cat=trial_lgb.params['cat_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693361650789024"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = mod.RegMod(ord_vars=region_cats['reg'],\n",
    "                 dat_vars=['date'],\n",
    "                 ide_vars=ele_cats['ele_std'] + xy_cats['both'] + sl_cats['lagNone'] + sat_2500,\n",
    "                 y='severity',\n",
    "                 mod = mod.XGBRegressor(n_estimators=60, max_depth=9))\n",
    "xgb.fit(train_dat,weight=False)\n",
    "xgb.met_eval(train_dat,ret=True,weight=trial_xgb.params['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = mod.EnsMod(mods={'xgb': xgb, 'cat': cat, 'lig': lig})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now getting files for out of sample data\n",
    "test = feat.get_data(data_type='test')\n",
    "test['pred'] = rm.predict_int(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    2512\n",
      "4    2091\n",
      "1    1241\n",
      "3     666\n",
      "Name: severity, dtype: int64\n",
      "Date sub_2023_02_16.csv same as current\n",
      "0    6510\n",
      "Name: dif_2023_02_16, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "form_dat = feat.sub_format(test)\n",
    "print(form_dat['severity'].value_counts())\n",
    "\n",
    "# function to check if similar to any past submissions\n",
    "mod.check_similar(form_dat)\n",
    "\n",
    "# Checking to see differences compared to best submission so far\n",
    "current = form_dat.copy()\n",
    "mod.check_day(current,day=\"sub_2023_02_16.csv\")\n",
    "current.groupby('region',as_index=False)['dif_2023_02_16'].value_counts()\n",
    "\n",
    "# Saving the data and model\n",
    "form_dat.to_csv(f'sub_BESTRESULTS_0216.csv',index=False)\n",
    "mod.save_model(rm,f'mod_BESTRESULTS_0216')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
